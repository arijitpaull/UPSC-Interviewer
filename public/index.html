<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>UPSC Interview Simulation</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: radial-gradient(circle at center, #101010 0%, #000000 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            overflow: hidden;
        }

        #container {
            position: relative;
            width: 100%;
            height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
        }

        #interviewButton {
            width: 200px;
            height: 200px;
            border-radius: 50%;
            background: #eaefff;
            border: none;
            cursor: pointer;
            display: flex;
            justify-content: center;
            align-items: center;
            transition: box-shadow 0.3s ease;
            position: relative;
            box-shadow: 0 0 40px rgba(234, 239, 255, 0.3);
            transform-origin: center;
        }

        #interviewButton:hover {
            transform: scale(1.05);
            box-shadow: 0 0 60px rgba(234, 239, 255, 0.5);
        }

        #interviewButton:active {
            transform: scale(0.98);
        }

        #interviewButton span {
            color: #101010;
            font-size: 13px;
            font-weight: 400;
            letter-spacing: 0.5px;
            transition: opacity 0.3s ease;
            text-align: center;
        }

        #interviewButton.active {
            animation: none;
        }

        #interviewButton.speaking {
            animation: none;
        }

        @keyframes pulse {
            0%, 100% {
                transform: scale(1);
                box-shadow: 0 0 40px rgba(234, 239, 255, 0.3);
            }
            50% {
                transform: scale(1.1);
                box-shadow: 0 0 80px rgba(234, 239, 255, 0.6);
            }
        }

        .fade-out {
            opacity: 0 !important;
        }

        #statusText {
            position: absolute;
            bottom: 80px;
            color: #eaefff;
            font-size: 14px;
            opacity: 0;
            transition: opacity 0.3s ease;
            text-align: center;
            max-width: 80%;
        }

        #statusText.visible {
            opacity: 0.7;
        }

        #endButton {
            position: absolute;
            top: 40px;
            right: 40px;
            padding: 10px 20px;
            background: transparent;
            border: 1px solid #333333;
            color: #888888;
            border-radius: 0;
            cursor: pointer;
            font-size: 11px;
            font-weight: 400;
            opacity: 0;
            transition: all 0.3s ease;
            pointer-events: none;
            text-transform: uppercase;
            letter-spacing: 1px;
        }

        #endButton.visible {
            opacity: 1;
            pointer-events: all;
        }

        #endButton:hover {
            background: transparent;
            border-color: #666666;
            color: #ffffff;
        }

        .error-message {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            background: rgba(255, 100, 100, 0.1);
            border: 1px solid rgba(255, 100, 100, 0.3);
            color: #ffaaaa;
            padding: 20px 30px;
            border-radius: 12px;
            opacity: 0;
            pointer-events: none;
            transition: opacity 0.3s ease;
            max-width: 80%;
            text-align: center;
        }

        .error-message.visible {
            opacity: 1;
        }

        @media (max-width: 768px) {
            #interviewButton {
                width: 160px;
                height: 160px;
            }

            #interviewButton span {
                font-size: 12px;
            }

            #endButton {
                top: 20px;
                right: 20px;
                padding: 8px 16px;
                font-size: 10px;
            }

            #statusText {
                font-size: 13px;
                bottom: 60px;
            }
        }

        @media (max-width: 480px) {
            #interviewButton {
                width: 140px;
                height: 140px;
            }

            #interviewButton span {
                font-size: 11px;
            }
        }

        /* Metrics Overlay Styles - Minimal Monochrome */
#metricsOverlay {
    position: fixed;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    background: rgba(0, 0, 0, 0.97);
    z-index: 1000;
    opacity: 0;
    transition: opacity 0.3s ease;
    overflow-y: auto;
    padding: 20px;
}

#metricsOverlay.visible {
    opacity: 1;
}

.metrics-modal {
    max-width: 800px;
    margin: 0 auto;
    background: #000000;
    border: 1px solid #333333;
}

.metrics-header {
    padding: 40px 40px 20px;
    border-bottom: 1px solid #222222;
    display: flex;
    justify-content: space-between;
    align-items: center;
}

.metrics-header h2 {
    color: #ffffff;
    font-size: 18px;
    font-weight: 400;
    margin: 0;
    letter-spacing: 1px;
    text-transform: uppercase;
}

.close-metrics {
    background: none;
    border: 1px solid #333333;
    color: #888888;
    font-size: 20px;
    width: 32px;
    height: 32px;
    cursor: pointer;
    transition: all 0.2s ease;
    font-weight: 300;
}

.close-metrics:hover {
    border-color: #666666;
    color: #ffffff;
}

.metrics-content {
    padding: 30px 40px;
}

.metrics-section {
    margin-bottom: 40px;
    padding-bottom: 30px;
    border-bottom: 1px solid #1a1a1a;
}

.metrics-section:last-child {
    border-bottom: none;
}

.metrics-section h3 {
    color: #ffffff;
    font-size: 12px;
    font-weight: 400;
    margin-bottom: 20px;
    letter-spacing: 2px;
    text-transform: uppercase;
}

.scores-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(140px, 1fr));
    gap: 20px;
    margin-top: 20px;
}

.score-card {
    background: #0a0a0a;
    padding: 20px;
    border: 1px solid #1a1a1a;
    text-align: left;
}

.score-label {
    color: #666666;
    font-size: 10px;
    margin-bottom: 8px;
    text-transform: uppercase;
    letter-spacing: 1px;
}

.score-value {
    color: #ffffff;
    font-size: 28px;
    font-weight: 300;
    margin-bottom: 12px;
    font-family: 'Courier New', monospace;
}

.score-bar {
    height: 2px;
    background: #1a1a1a;
    overflow: hidden;
}

.score-fill {
    height: 100%;
    background: #ffffff;
    transition: width 0.8s ease;
}

.stats-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(180px, 1fr));
    gap: 15px;
    margin-top: 15px;
}

.stat-item {
    background: #0a0a0a;
    padding: 15px 20px;
    border: 1px solid #1a1a1a;
    display: flex;
    justify-content: space-between;
    align-items: center;
}

.stat-label {
    color: #666666;
    font-size: 11px;
    text-transform: uppercase;
    letter-spacing: 1px;
}

.stat-value {
    color: #ffffff;
    font-size: 16px;
    font-weight: 300;
    font-family: 'Courier New', monospace;
}

.stat-value.warning {
    color: #888888;
}

.strengths-list, .improvements-list {
    list-style: none;
    padding: 0;
    margin: 15px 0;
}

.strength-item, .improvement-item {
    background: #0a0a0a;
    padding: 15px 20px;
    margin-bottom: 10px;
    border-left: 2px solid #333333;
    color: #cccccc;
    font-size: 13px;
    line-height: 1.6;
    font-weight: 300;
}

.strength-item {
    border-left-color: #ffffff;
}

.improvement-item {
    border-left-color: #666666;
}

.detailed-feedback {
    margin-top: 15px;
}

.feedback-item {
    background: #0a0a0a;
    padding: 20px;
    margin-bottom: 15px;
    border: 1px solid #1a1a1a;
}

.feedback-item h4 {
    color: #ffffff;
    font-size: 11px;
    font-weight: 400;
    margin: 0 0 12px 0;
    text-transform: uppercase;
    letter-spacing: 1px;
}

.feedback-item p {
    color: #999999;
    font-size: 13px;
    line-height: 1.7;
    margin: 0;
    font-weight: 300;
}

.overall-feedback {
    background: #0a0a0a;
    padding: 25px;
    border: 1px solid #1a1a1a;
    color: #cccccc;
    font-size: 13px;
    line-height: 1.8;
    margin-top: 15px;
    font-weight: 300;
}

.metrics-footer {
    padding: 30px 40px;
    border-top: 1px solid #222222;
    display: flex;
    justify-content: center;
}

.btn-primary {
    background: #ffffff;
    color: #000000;
    border: none;
    padding: 12px 30px;
    font-size: 11px;
    font-weight: 400;
    cursor: pointer;
    transition: all 0.2s ease;
    text-transform: uppercase;
    letter-spacing: 1px;
}

.btn-primary:hover {
    background: #dddddd;
}

@media (max-width: 768px) {
    .metrics-modal {
        margin: 0;
    }

    .metrics-header {
        padding: 30px 20px 15px;
    }

    .metrics-header h2 {
        font-size: 14px;
    }

    .metrics-content {
        padding: 20px;
    }

    .scores-grid {
        grid-template-columns: 1fr;
    }

    .stats-grid {
        grid-template-columns: 1fr;
    }
}
    </style>
</head>
<body>
    <div id="container">
        <button id="interviewButton">
            <span>Begin Interview</span>
        </button>
        <div id="statusText"></div>
        <button id="endButton">End Interview</button>
        <div id="errorMessage" class="error-message"></div>
    </div>

    <script>
        const SYSTEM_PROMPT_BASE = `You are a UPSC Civil Services Personality Test Board Member interviewing candidate Tanya Singh.
Your task is to conduct a realistic UPSC interview exactly like an officer in the UPSC board room.
Use Tanya's DAF (attached by the user) as the factual base for your questions.

INTERVIEWER PERSONALITY
Male, age 55‚Äì62
Retired IAS officer with experience in Personnel, Home, and Finance
Formal, polite, neutral
Not very strict but definitely not lenient
Short, sharp questions
Professional, unemotional tone
Gives zero validation
Probes deeply, uses follow-ups, exposes weak logic
No long lectures, no hints, no softening
Asks unpredictable on-the-spot questions

YOUR PERSONAL INTERESTS (for this session):
{INTERESTS}

CRITICAL: When Tanya mentions any of your personal interests during her responses, you should:
1. Show genuine interest naturally: "Oh, that's interesting..." or "I'm quite interested in that myself..."
2. Share a brief personal perspective or insight (1-2 sentences)
3. Engage in 2-3 turns of natural discussion on that topic
4. Then smoothly transition back to formal questioning
5. Do NOT announce you have these interests upfront - only reveal them when relevant

CONDUCT RULES
Start the simulation directly:
"Good morning, Ms. Singh. Please introduce yourself."
Ask one question at a time.
Use Tanya's DAF heavily ‚Äî her background, domicile, education, optional (Economics), roles, volunteering, achievements, preferences, everything.
Ask follow-up questions:
"Why?"
"How exactly?"
"Can you justify that?"
"What is the administrative implication?"
"What if you were wrong?"
"Give me a concrete example."
"How would you apply this on the ground?"
"What data will you use?"
"Who are the stakeholders?"

Ask random on-the-spot questions based on:
DAF details, her optional subject, volunteering experience, leadership roles, hobbies, home state/area issues, service preference, ethical dilemmas, situational administrative problems, national & international current affairs, economics-related policy, Delhi-specific governance issues, India's global positioning.

Do not praise, correct, validate, or tell the candidate if she is right or wrong.
Never give hints. Just question, probe, and move on.
Maintain UPSC decorum always.

Keep responses conversational and concise for voice interaction. Maximum 2-3 sentences per response unless engaging in shared interest discussion.

IMPORTANT: If the candidate interrupts you or speaks while you're speaking, immediately pause and let them complete their thought. Acknowledge politely: "Please continue" or "Yes, go ahead" before resuming.`;

        let conversationHistory = [];
        let isInterviewActive = false;
        let mediaRecorder = null;
        let audioChunks = [];
        let audioContext = null;
        let analyser = null;
        let animationFrameId = null;
        let isProcessing = false;
        let sessionId = null;
        let sessionInterests = [];
        let systemPrompt = '';
        
        // Advanced features
        let silenceDetectionTimer = null;
        let isSpeaking = false;
        let currentAudio = null;
        let interruptionDetected = false;
        let pauseThreshold = 1500; // 1.5 seconds of silence triggers interviewer
        let responseMetrics = [];

        const button = document.getElementById('interviewButton');
        const buttonText = button.querySelector('span');
        const statusText = document.getElementById('statusText');
        const endButton = document.getElementById('endButton');
        const errorMessage = document.getElementById('errorMessage');

        // Show error message
        function showError(message) {
            errorMessage.textContent = message;
            errorMessage.classList.add('visible');
            setTimeout(() => {
                errorMessage.classList.remove('visible');
            }, 5000);
        }

        // Initialize audio context for visualization
        function initAudioContext() {
            if (!audioContext) {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
            }
        }

        // Start interview
        async function startInterview() {
            // Pre-check microphone permission
            try {
                console.log('Checking microphone access...');
                
                // Request permission first (this shows the browser permission dialog)
                const testStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                console.log('‚úÖ Microphone permission granted');
                
                // Stop the test stream immediately
                testStream.getTracks().forEach(track => track.stop());
                
            } catch (error) {
                console.error('Microphone permission check failed:', error);
                
                if (error.name === 'NotAllowedError' || error.name === 'PermissionDeniedError') {
                    showError('Please allow microphone access to start the interview.\n\n1. Click "Allow" when prompted\n2. Or click the üîí icon in address bar\n3. Then reload and try again');
                } else if (error.name === 'NotFoundError') {
                    showError('No microphone detected. Please connect a microphone.');
                } else {
                    showError('Microphone error: ' + error.message);
                }
                return;
            }
            
            isInterviewActive = true;
            conversationHistory = [];
            responseMetrics = [];
            
            // Initialize session with random interests
            try {
                const sessionResponse = await fetch('/api/session/init', {
                    method: 'POST'
                });
                const sessionData = await sessionResponse.json();
                sessionId = sessionData.sessionId;
                sessionInterests = sessionData.interests;
                
                // Create system prompt with interests
                systemPrompt = SYSTEM_PROMPT_BASE.replace(
                    '{INTERESTS}',
                    `- ${sessionInterests[0]}\n- ${sessionInterests[1]}`
                );
                
                console.log('Session initialized with interests:', sessionInterests);
            } catch (error) {
                console.error('Session init error:', error);
                showError('Failed to initialize session');
                return;
            }
            
            // Fade out text
            buttonText.classList.add('fade-out');
            setTimeout(() => {
                buttonText.style.display = 'none';
            }, 300);

            // Show end button
            endButton.classList.add('visible');

            // Start with greeting from interviewer
            updateStatus('Interviewer is speaking...');
            await speakText("Good morning, Ms. Singh. Please introduce yourself.");
            
            // Start continuous listening with pause detection
            setTimeout(() => startContinuousListening(), 500);
        }

        // End interview and show metrics
        async function endInterview() {
            if (!isInterviewActive) return;
            
            isInterviewActive = false;
            isProcessing = false;
            
            // Stop any ongoing recording
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
            }

            // Stop current audio
            if (currentAudio) {
                currentAudio.pause();
                currentAudio = null;
            }

            // Stop animation
            if (animationFrameId) {
                cancelAnimationFrame(animationFrameId);
            }
            
            // Clear silence detection
            if (silenceDetectionTimer) {
                clearTimeout(silenceDetectionTimer);
            }

            // Show loading state
            updateStatus('Generating your performance report...');
            button.classList.add('speaking');
            
            try {
                // Generate metrics report
                const reportResponse = await fetch('/api/session/report', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        sessionId,
                        conversationHistory
                    })
                });
                
                if (reportResponse.ok) {
                    const report = await reportResponse.json();
                    displayMetricsReport(report);
                } else {
                    throw new Error('Failed to generate report');
                }
            } catch (error) {
                console.error('Report generation error:', error);
                showError('Failed to generate performance report');
            }
            
            // Reset UI
            button.classList.remove('active', 'speaking');
            button.style.transform = 'scale(1)';
            buttonText.style.display = 'block';
            buttonText.textContent = 'Begin New Interview';
            buttonText.classList.remove('fade-out');
            button.onclick = () => {
                if (!isInterviewActive) {
                    // Reset and start new
                    conversationHistory = [];
                    responseMetrics = [];
                    sessionId = null;
                    hideMetricsReport();
                    buttonText.textContent = 'Begin Interview';
                    startInterview();
                }
            };
            
            statusText.classList.remove('visible');
            endButton.classList.remove('visible');
        }

        // Update status text
        function updateStatus(text) {
            statusText.textContent = text;
            statusText.classList.add('visible');
        }

        // Text-to-speech using backend
        async function speakText(text) {
            try {
                button.classList.add('speaking');
                
                const response = await fetch('/api/tts', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({ text })
                });

                if (!response.ok) {
                    throw new Error('TTS failed');
                }

                const audioBlob = await response.blob();
                const audioUrl = URL.createObjectURL(audioBlob);
                const audio = new Audio(audioUrl);
                
                // Store current audio for interruption detection
                currentAudio = audio;

                // Create audio context for visualization
                if (!audioContext) {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                }
                
                const source = audioContext.createMediaElementSource(audio);
                const analyserNode = audioContext.createAnalyser();
                analyserNode.fftSize = 256;
                
                source.connect(analyserNode);
                analyserNode.connect(audioContext.destination);
                
                // Visualize audio in real-time
                let visualizationFrameId;
                function visualizeAudio() {
                    const bufferLength = analyserNode.frequencyBinCount;
                    const dataArray = new Uint8Array(bufferLength);
                    analyserNode.getByteFrequencyData(dataArray);
                    
                    // Calculate average volume
                    const average = dataArray.reduce((a, b) => a + b) / bufferLength;
                    
                    // Scale button based on audio level (smoother, more subtle)
                    const scale = 1 + (average / 255) * 0.25; // Max 1.25x scale
                    button.style.transform = `scale(${scale})`;
                    
                    if (currentAudio && !currentAudio.paused && !currentAudio.ended) {
                        visualizationFrameId = requestAnimationFrame(visualizeAudio);
                    }
                }

                return new Promise((resolve, reject) => {
                    audio.onplay = () => {
                        visualizeAudio();
                    };
                    
                    audio.onended = () => {
                        if (visualizationFrameId) {
                            cancelAnimationFrame(visualizationFrameId);
                        }
                        button.classList.remove('speaking');
                        button.style.transform = 'scale(1)';
                        URL.revokeObjectURL(audioUrl);
                        currentAudio = null;
                        resolve();
                    };
                    
                    audio.onerror = () => {
                        if (visualizationFrameId) {
                            cancelAnimationFrame(visualizationFrameId);
                        }
                        button.classList.remove('speaking');
                        button.style.transform = 'scale(1)';
                        currentAudio = null;
                        reject(new Error('Audio playback failed'));
                    };
                    
                    // If audio is paused (interrupted), resolve early
                    audio.onpause = () => {
                        if (visualizationFrameId) {
                            cancelAnimationFrame(visualizationFrameId);
                        }
                        if (interruptionDetected) {
                            button.classList.remove('speaking');
                            button.style.transform = 'scale(1)';
                            URL.revokeObjectURL(audioUrl);
                            resolve();
                        }
                    };
                    
                    audio.play().catch(err => {
                        console.error('Audio play error:', err);
                        if (visualizationFrameId) {
                            cancelAnimationFrame(visualizationFrameId);
                        }
                        button.classList.remove('speaking');
                        button.style.transform = 'scale(1)';
                        currentAudio = null;
                        reject(err);
                    });
                });
            } catch (error) {
                console.error('Speech error:', error);
                button.classList.remove('speaking');
                button.style.transform = 'scale(1)';
                currentAudio = null;
                showError('Speech synthesis error. Please check your connection.');
                throw error;
            }
        }

        // Start continuous listening with pause and interruption detection
        async function startContinuousListening() {
            if (!isInterviewActive || isProcessing) return;

            try {
                // First check if we have permission
                if (navigator.permissions && navigator.permissions.query) {
                    try {
                        const permissionStatus = await navigator.permissions.query({ name: 'microphone' });
                        console.log('Microphone permission status:', permissionStatus.state);
                        
                        if (permissionStatus.state === 'denied') {
                            showError('Microphone blocked. Please click the üîí icon in your address bar and allow microphone access, then reload the page.');
                            updateStatus('Microphone permission required');
                            return;
                        }
                    } catch (permErr) {
                        console.log('Permission query not supported, proceeding with getUserMedia');
                    }
                }

                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    } 
                });
                
                console.log('‚úÖ Microphone access granted');
                
                initAudioContext();
                const source = audioContext.createMediaStreamSource(stream);
                
                // Create a separate analyser for microphone input (don't reuse the TTS analyser)
                const micAnalyser = audioContext.createAnalyser();
                micAnalyser.fftSize = 256;
                source.connect(micAnalyser);
                
                // Store reference for speech detection
                analyser = micAnalyser;
                
                mediaRecorder = new MediaRecorder(stream, {
                    mimeType: 'audio/webm'
                });
                audioChunks = [];

                mediaRecorder.ondataavailable = (event) => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = async () => {
                    stream.getTracks().forEach(track => track.stop());
                    
                    if (animationFrameId) {
                        cancelAnimationFrame(animationFrameId);
                    }
                    button.classList.remove('active');
                    button.style.transform = 'scale(1)';

                    if (!isInterviewActive) return;

                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    
                    // Check if this was an interruption
                    if (interruptionDetected) {
                        await handleInterruption(audioBlob);
                    } else {
                        await processUserSpeech(audioBlob);
                    }
                };

                updateStatus('Listening... (Speak naturally, I\'ll know when you\'re done)');
                button.classList.add('active');
                mediaRecorder.start();
                
                // Start silence and volume detection
                detectSpeechAndPauses();
                
                // Allow manual submission by clicking
                button.onclick = () => {
                    if (mediaRecorder && mediaRecorder.state === 'recording') {
                        if (silenceDetectionTimer) {
                            clearTimeout(silenceDetectionTimer);
                        }
                        mediaRecorder.stop();
                        isSpeaking = false;
                        updateStatus('Processing your response...');
                    }
                };

            } catch (error) {
                console.error('Microphone error:', error);
                
                // Detailed error messages
                if (error.name === 'NotAllowedError' || error.name === 'PermissionDeniedError') {
                    showError('Microphone permission denied. Please:\n1. Click the üîí icon in your address bar\n2. Allow microphone access\n3. Reload the page (Ctrl/Cmd + R)');
                    updateStatus('Allow microphone to continue');
                } else if (error.name === 'NotFoundError' || error.name === 'DevicesNotFoundError') {
                    showError('No microphone found. Please connect a microphone and reload.');
                    updateStatus('Microphone not detected');
                } else if (error.name === 'NotReadableError' || error.name === 'TrackStartError') {
                    showError('Microphone is being used by another application. Please close other apps using the microphone and reload.');
                    updateStatus('Microphone in use by another app');
                } else {
                    showError(`Microphone error: ${error.message}. Please reload the page and try again.`);
                    updateStatus('Microphone error');
                }
                
                // Reset interview state
                isInterviewActive = false;
                button.classList.remove('active', 'speaking');
                buttonText.style.display = 'block';
                buttonText.textContent = 'Begin Interview';
                buttonText.classList.remove('fade-out');
                endButton.classList.remove('visible');
            }
        }
        
        // Detect speech activity and pauses
        function detectSpeechAndPauses() {
            const bufferLength = analyser.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);
            const speechThreshold = 30; // Adjust based on testing
            let consecutiveSilenceFrames = 0;
            const silenceFramesNeeded = 75; // ~1.5 seconds at 60fps

            function checkAudioLevel() {
                if (!isInterviewActive || !mediaRecorder || mediaRecorder.state !== 'recording') {
                    return;
                }

                analyser.getByteFrequencyData(dataArray);
                const average = dataArray.reduce((a, b) => a + b) / bufferLength;

                // Detect if user is speaking
                if (average > speechThreshold) {
                    consecutiveSilenceFrames = 0;
                    
                    if (!isSpeaking) {
                        isSpeaking = true;
                        
                        // If interviewer is currently speaking, this is an interruption
                        if (currentAudio && !currentAudio.paused) {
                            console.log('Interruption detected!');
                            interruptionDetected = true;
                            currentAudio.pause();
                            currentAudio = null;
                            button.classList.remove('speaking');
                        }
                    }
                    
                    // Visualize speaking
                    const scale = 1 + (average / 255) * 0.3;
                    button.style.transform = `scale(${scale})`;
                } else {
                    // Silence detected
                    consecutiveSilenceFrames++;
                    button.style.transform = 'scale(1)';
                    
                    // After enough silence, stop recording automatically
                    if (isSpeaking && consecutiveSilenceFrames >= silenceFramesNeeded) {
                        console.log('Pause detected, processing response');
                        isSpeaking = false;
                        if (mediaRecorder && mediaRecorder.state === 'recording') {
                            mediaRecorder.stop();
                        }
                        return;
                    }
                }

                animationFrameId = requestAnimationFrame(checkAudioLevel);
            }

            checkAudioLevel();
        }
        
        // Handle interruption
        async function handleInterruption(audioBlob) {
            console.log('Processing interruption...');
            
            // Track the interruption
            if (sessionId) {
                await fetch('/api/session/track', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        sessionId,
                        interruptionDetected: true,
                        metrics: {}
                    })
                });
            }
            
            interruptionDetected = false;
            
            // Process what user said during interruption
            await processUserSpeech(audioBlob, true);
        }

        // Process user speech
        async function processUserSpeech(audioBlob, wasInterruption = false) {
            if (isProcessing) return;
            isProcessing = true;

            try {
                // Convert audio to text using backend
                const formData = new FormData();
                formData.append('audio', audioBlob, 'audio.webm');

                const transcriptionResponse = await fetch('/api/stt', {
                    method: 'POST',
                    body: formData
                });

                if (!transcriptionResponse.ok) {
                    throw new Error('Transcription failed');
                }

                const transcription = await transcriptionResponse.json();
                const userText = transcription.text;
                const speechMetrics = transcription.metrics;

                if (!userText || userText.trim().length === 0) {
                    updateStatus('No speech detected. Please continue...');
                    isProcessing = false;
                    setTimeout(() => startContinuousListening(), 1000);
                    return;
                }

                console.log('User said:', userText);
                console.log('Speech metrics:', speechMetrics);
                
                // Store metrics
                responseMetrics.push(speechMetrics);
                
                // Track metrics
                if (sessionId) {
                    await fetch('/api/session/track', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json'
                        },
                        body: JSON.stringify({
                            sessionId,
                            metrics: speechMetrics,
                            interruptionDetected: wasInterruption
                        })
                    });
                }

                // Add to conversation history
                conversationHistory.push({
                    role: 'user',
                    content: userText
                });

                // Get interviewer response
                updateStatus('Interviewer is thinking...');
                const interviewerResponse = await getInterviewerResponse();

                console.log('Interviewer responds:', interviewerResponse);

                // Add to conversation history
                conversationHistory.push({
                    role: 'assistant',
                    content: interviewerResponse
                });

                // Speak the response
                updateStatus('Interviewer is speaking...');
                await speakText(interviewerResponse);

                // Continue listening
                isProcessing = false;
                interruptionDetected = false;
                setTimeout(() => startContinuousListening(), 500);

            } catch (error) {
                console.error('Processing error:', error);
                showError('Error processing response. Retrying...');
                isProcessing = false;
                setTimeout(() => startContinuousListening(), 2000);
            }
        }

        // Get response from GPT-4 via backend
        async function getInterviewerResponse() {
            try {
                const messages = [
                    { role: 'system', content: systemPrompt },
                    ...conversationHistory
                ];

                const response = await fetch('/api/chat', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({ messages })
                });

                if (!response.ok) {
                    throw new Error('Chat API request failed');
                }

                const data = await response.json();
                return data.choices[0].message.content;

            } catch (error) {
                console.error('API error:', error);
                return "I apologize, there was a technical issue. Could you please repeat that?";
            }
        }

        // Display metrics report
        function displayMetricsReport(report) {
            const { analysis, rawMetrics } = report;
            
            // Create metrics overlay
            const overlay = document.createElement('div');
            overlay.id = 'metricsOverlay';
            overlay.innerHTML = `
                <div class="metrics-modal">
                    <div class="metrics-header">
                        <h2>üìä Interview Performance Report</h2>
                        <button class="close-metrics" onclick="hideMetricsReport()">√ó</button>
                    </div>
                    
                    <div class="metrics-content">
                        <div class="metrics-section">
                            <h3>Overall Scores</h3>
                            <div class="scores-grid">
                                <div class="score-card">
                                    <div class="score-label">Content Quality</div>
                                    <div class="score-value">${analysis.scores.content.score}/10</div>
                                    <div class="score-bar">
                                        <div class="score-fill" style="width: ${analysis.scores.content.score * 10}%"></div>
                                    </div>
                                </div>
                                <div class="score-card">
                                    <div class="score-label">Communication</div>
                                    <div class="score-value">${analysis.scores.communication.score}/10</div>
                                    <div class="score-bar">
                                        <div class="score-fill" style="width: ${analysis.scores.communication.score * 10}%"></div>
                                    </div>
                                </div>
                                <div class="score-card">
                                    <div class="score-label">Confidence</div>
                                    <div class="score-value">${analysis.scores.confidence.score}/10</div>
                                    <div class="score-bar">
                                        <div class="score-fill" style="width: ${analysis.scores.confidence.score * 10}%"></div>
                                    </div>
                                </div>
                                <div class="score-card">
                                    <div class="score-label">Knowledge Depth</div>
                                    <div class="score-value">${analysis.scores.knowledge.score}/10</div>
                                    <div class="score-bar">
                                        <div class="score-fill" style="width: ${analysis.scores.knowledge.score * 10}%"></div>
                                    </div>
                                </div>
                                <div class="score-card">
                                    <div class="score-label">Interview Etiquette</div>
                                    <div class="score-value">${analysis.scores.etiquette.score}/10</div>
                                    <div class="score-bar">
                                        <div class="score-fill" style="width: ${analysis.scores.etiquette.score * 10}%"></div>
                                    </div>
                                </div>
                            </div>
                        </div>
                        
                        <div class="metrics-section">
                            <h3>üìà Quick Stats</h3>
                            <div class="stats-grid">
                                <div class="stat-item">
                                    <span class="stat-label">Total Responses:</span>
                                    <span class="stat-value">${rawMetrics.totalResponses}</span>
                                </div>
                                <div class="stat-item">
                                    <span class="stat-label">Interruptions:</span>
                                    <span class="stat-value ${rawMetrics.interruptions > 0 ? 'warning' : ''}">${rawMetrics.interruptions}</span>
                                </div>
                                <div class="stat-item">
                                    <span class="stat-label">Avg. Filler Words:</span>
                                    <span class="stat-value ${rawMetrics.avgFillers > 3 ? 'warning' : ''}">${rawMetrics.avgFillers}</span>
                                </div>
                                <div class="stat-item">
                                    <span class="stat-label">Avg. Repetitions:</span>
                                    <span class="stat-value ${rawMetrics.avgRepetitions > 2 ? 'warning' : ''}">${rawMetrics.avgRepetitions}</span>
                                </div>
                            </div>
                        </div>
                        
                        <div class="metrics-section">
                            <h3>üí™ Your Strengths</h3>
                            <ul class="strengths-list">
                                ${analysis.strengths.map(s => `<li class="strength-item">‚úì ${s}</li>`).join('')}
                            </ul>
                        </div>
                        
                        <div class="metrics-section">
                            <h3>üéØ Areas for Improvement</h3>
                            <ul class="improvements-list">
                                ${analysis.improvements.map(i => `<li class="improvement-item">‚Üí ${i}</li>`).join('')}
                            </ul>
                        </div>
                        
                        <div class="metrics-section">
                            <h3>üí¨ Detailed Feedback</h3>
                            ${generateDetailedFeedback(analysis)}
                        </div>
                        
                        <div class="metrics-section">
                            <h3>üìù Overall Impression</h3>
                            <p class="overall-feedback">${analysis.overall}</p>
                        </div>
                    </div>
                    
                    <div class="metrics-footer">
                        <button class="btn-primary" onclick="hideMetricsReport()">Start New Interview</button>
                    </div>
                </div>
            `;
            
            document.body.appendChild(overlay);
            
            // Animate in
            setTimeout(() => {
                overlay.classList.add('visible');
            }, 100);
        }
        
        function generateDetailedFeedback(analysis) {
            let html = '<div class="detailed-feedback">';
            
            for (const [key, data] of Object.entries(analysis.scores)) {
                html += `
                    <div class="feedback-item">
                        <h4>${formatScoreTitle(key)}</h4>
                        <p>${data.feedback}</p>
                    </div>
                `;
            }
            
            if (analysis.detailedNotes) {
                for (const [key, note] of Object.entries(analysis.detailedNotes)) {
                    if (note) {
                        html += `
                            <div class="feedback-item">
                                <h4>${formatScoreTitle(key)}</h4>
                                <p>${note}</p>
                            </div>
                        `;
                    }
                }
            }
            
            html += '</div>';
            return html;
        }
        
        function formatScoreTitle(key) {
            const titles = {
                'content': 'Content Quality',
                'communication': 'Communication Skills',
                'confidence': 'Confidence & Composure',
                'knowledge': 'Knowledge Depth',
                'etiquette': 'Interview Etiquette',
                'fillers': 'Filler Words Usage',
                'interruptions': 'Interruption Handling',
                'repetitions': 'Word Repetitions',
                'pacing': 'Response Pacing'
            };
            return titles[key] || key;
        }
        
        function hideMetricsReport() {
            const overlay = document.getElementById('metricsOverlay');
            if (overlay) {
                overlay.classList.remove('visible');
                setTimeout(() => {
                    overlay.remove();
                }, 300);
            }
        }

        // Event listeners
        button.addEventListener('click', () => {
            if (!isInterviewActive) {
                startInterview();
            }
        });

        endButton.addEventListener('click', endInterview);

        // Ensure audio context is resumed on user interaction
        document.addEventListener('click', () => {
            if (audioContext && audioContext.state === 'suspended') {
                audioContext.resume();
            }
        }, { once: true });
    </script>
</body>
</html>